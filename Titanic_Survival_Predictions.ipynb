{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary tools\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import types\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, classification_report, f1_score, jaccard_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_validate\n",
    "from statistics import mean\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Titanic_train.csv')\n",
    "test_df = pd.read_csv('titanic_test.csv')\n",
    "example_df = pd.read_csv('titanic_gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(train_df.Age.min(), train_df.Age.max()+1, 10)\n",
    "g = sns.FacetGrid(train_df, col=\"Embarked\", hue=\"Survived\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'Age', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Dataframe Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelling_df = train_df.copy()\n",
    "modelling_df['Child'] = modelling_df['Age']<18\n",
    "modelling_df['Child'].replace([True, False], [1, 0], inplace = True)\n",
    "modelling_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_age_features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Child']\n",
    "no_age_features = ['Pclass', 'Sex', 'Fare', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_df['Embarked'].replace(['Q', 'S', 'C'], [0, 1, 2], inplace = True)\n",
    "modelling_df['Sex'].replace(['male', 'female'], [0, 1], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Child</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name  Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    0  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina    1  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1   \n",
       "4                             Allen, Mr. William Henry    0  35.0      0   \n",
       "..                                                 ...  ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    0  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith    1  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"    1   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    0  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    0  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin  Embarked  Child  \n",
       "0        0         A/5 21171   7.2500   NaN       1.0      0  \n",
       "1        0          PC 17599  71.2833   C85       2.0      0  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN       1.0      0  \n",
       "3        0            113803  53.1000  C123       1.0      0  \n",
       "4        0            373450   8.0500   NaN       1.0      0  \n",
       "..     ...               ...      ...   ...       ...    ...  \n",
       "886      0            211536  13.0000   NaN       1.0      0  \n",
       "887      0            112053  30.0000   B42       1.0      0  \n",
       "888      2        W./C. 6607  23.4500   NaN       1.0      0  \n",
       "889      0            111369  30.0000  C148       2.0      0  \n",
       "890      0            370376   7.7500   NaN       0.0      0  \n",
       "\n",
       "[889 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature in no_age_features:\n",
    "    for number in modelling_df.index:\n",
    "        if pd.isna(modelling_df.loc[number, feature]):\n",
    "            modelling_df.drop(index = number, inplace = True)\n",
    "modelling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_replace = modelling_df[pd.isna(modelling_df['Age'])].index.tolist()\n",
    "no_age_modelling = modelling_df.iloc[age_replace]\n",
    "age_modelling = modelling_df.drop(index = age_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_survived_values = age_modelling['Survived'].tolist()\n",
    "no_age_survived_values = no_age_modelling['Survived'].tolist()\n",
    "age_y = np.array(age_survived_values)\n",
    "no_age_y = np.array(no_age_survived_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformed_df = pd.DataFrame(columns = features)\n",
    "for row in rows:\n",
    "    a_series = pd.Series(row, index = transformed_df.columns)\n",
    "    transformed_df = transformed_df.append(a_series, ignore_index=True)\n",
    "transformed_df['Survived'] = survived_values\n",
    "transformed_df.corr()##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90859974, -0.75613751, -0.52766856, -0.51637992, -0.31923045,\n",
       "        -0.43433598],\n",
       "       [-1.48298257,  1.32251077,  0.57709388,  0.69404605,  1.9091233 ,\n",
       "        -0.43433598],\n",
       "       [ 0.90859974,  1.32251077, -0.25147795, -0.50362035, -0.31923045,\n",
       "        -0.43433598],\n",
       "       [-1.48298257,  1.32251077,  0.36995092,  0.35032585, -0.31923045,\n",
       "        -0.43433598],\n",
       "       [ 0.90859974, -0.75613751,  0.36995092, -0.50125747, -0.31923045,\n",
       "        -0.43433598]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_train_X = age_modelling[new_age_features]\n",
    "no_age_train_X = no_age_modelling[no_age_features]\n",
    "age_train_X = preprocessing.StandardScaler().fit(age_train_X).transform(age_train_X.astype(float))\n",
    "no_age_train_X = preprocessing.StandardScaler().fit(no_age_train_X).transform(no_age_train_X.astype(float))\n",
    "age_train_X [0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Prediction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicting_df = test_df.copy()\n",
    "predicting_df['Child'] = predicting_df['Age']<18\n",
    "predicting_df['Child'].replace([True, False], [1, 0], inplace = True)\n",
    "predicting_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_df['Embarked'].replace(['Q', 'S', 'C'], [0, 1, 2], inplace = True)\n",
    "predicting_df['Sex'].replace(['male', 'female'], [0, 1], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_nan_replace = predicting_df[pd.isna(predicting_df['Fare'])].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_df.loc[fare_nan_replace, 'Fare'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_nan_replace = predicting_df[pd.isna(predicting_df['Age'])].index.tolist()\n",
    "no_age_predicting = predicting_df.iloc[age_nan_replace]\n",
    "age_predicting = predicting_df.drop(index = age_nan_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.01232494, -0.78709097,  0.29854934, -0.54148621, -2.22900041,\n",
       "        -0.37535779],\n",
       "       [ 1.01232494,  1.27050117,  1.18132793, -0.55506529, -0.34117353,\n",
       "        -0.37535779],\n",
       "       [-0.17109717, -0.78709097,  2.24066224, -0.51105446, -2.22900041,\n",
       "        -0.37535779],\n",
       "       [ 1.01232494, -0.78709097, -0.23111782, -0.52783999, -0.34117353,\n",
       "        -0.37535779],\n",
       "       [ 1.01232494,  1.27050117, -0.58422925, -0.46847654, -0.34117353,\n",
       "        -0.37535779]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_test_X = age_predicting[new_age_features]\n",
    "no_age_test_X = no_age_predicting[no_age_features]\n",
    "age_test_X = preprocessing.StandardScaler().fit(age_test_X).transform(age_test_X.astype(float))\n",
    "no_age_test_X = preprocessing.StandardScaler().fit(no_age_test_X).transform(no_age_test_X.astype(float))\n",
    "age_test_X [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k was 6, with a f1_score of 0.7951591140895167, a jaccard_score of 0.6638593850187638, an accuracy score of 0.7978233034571063, and an overall score of 0.7522806008551289\n"
     ]
    }
   ],
   "source": [
    "#list of scorers I will use\n",
    "scoring = ['accuracy', 'f1_weighted', 'jaccard_weighted']\n",
    "for scorer in scoring:\n",
    "    #making variables for each scorer\n",
    "    globals()['neighbors_'+scorer] = []\n",
    "    for k in range(1, 10):\n",
    "        #making a model for each k\n",
    "        neigh = KNeighborsClassifier(n_neighbors = k)\n",
    "        #evaluating the model with each scorer and storing the results in a list for each scorer\n",
    "        globals()['neighbors_'+scorer].append(cross_validate(neigh, age_train_X, age_y, scoring = scorer)['test_score'].mean())\n",
    "#averaging the score from each scorer for each k value and finding the best k\n",
    "average_neighbor_score = [(x + y + z)/3 for x, y, z in zip(neighbors_accuracy, neighbors_f1_weighted, neighbors_jaccard_weighted)]\n",
    "best_k = average_neighbor_score.index(max(average_neighbor_score))\n",
    "#getting each score for the best k\n",
    "for scorer in scoring:\n",
    "    globals()['best_'+scorer] = globals()['neighbors_'+scorer][best_k]\n",
    "#printing results\n",
    "age_neigh = KNeighborsClassifier(n_neighbors = best_k).fit(age_train_X, age_y)\n",
    "print('The best k was {}, with a f1_score of {}, a jaccard_score of {}, an accuracy score of {}, and an overall score of {}'.format(best_k, best_f1_weighted, best_jaccard_weighted, best_accuracy, mean([best_f1_weighted, best_jaccard_weighted, best_accuracy])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k was 5, with a f1_score of 0.7710570770330991, a jaccard_score of 0.6352195687391766, an accuracy score of 0.7801587301587303, and an overall score of 0.728811791977002\n"
     ]
    }
   ],
   "source": [
    "#list of scorers I will use\n",
    "scoring = ['accuracy', 'f1_weighted', 'jaccard_weighted']\n",
    "for scorer in scoring:\n",
    "    #making variables for each scorer\n",
    "    globals()['neighbors_'+scorer] = []\n",
    "    for k in range(1, 10):\n",
    "        #making a model for each k\n",
    "        neigh = KNeighborsClassifier(n_neighbors = k)\n",
    "        #evaluating the model with each scorer and storing the results in a list for each scorer\n",
    "        globals()['neighbors_'+scorer].append(cross_validate(neigh, no_age_train_X, no_age_y, scoring = scorer)['test_score'].mean())\n",
    "#averaging the score from each scorer for each k value and finding the best k\n",
    "average_neighbor_score = [(x + y + z)/3 for x, y, z in zip(neighbors_accuracy, neighbors_f1_weighted, neighbors_jaccard_weighted)]\n",
    "best_k = average_neighbor_score.index(max(average_neighbor_score))\n",
    "#getting each score for the best k\n",
    "for scorer in scoring:\n",
    "    globals()['best_'+scorer] = globals()['neighbors_'+scorer][best_k]\n",
    "#printing results\n",
    "no_age_neigh = KNeighborsClassifier(n_neighbors = best_k).fit(no_age_train_X, no_age_y)\n",
    "print('The best k was {}, with a f1_score of {}, a jaccard_score of {}, an accuracy score of {}, and an overall score of {}'.format(best_k, best_f1_weighted, best_jaccard_weighted, best_accuracy, mean([best_f1_weighted, best_jaccard_weighted, best_accuracy])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best c was 0.01, with a f1_score of 0.7767059184874958, a jaccard_score of 0.6392062018549647, an accuracy score of 0.779434649857185, and an overall score of 0.7317822567332152\n"
     ]
    }
   ],
   "source": [
    "#making list of c values\n",
    "c_list = np.arange(.01, 0.1, 0.01).tolist()\n",
    "for scorer in scoring:\n",
    "    #making variable for each scorer\n",
    "    globals()['svm_'+scorer] = []\n",
    "    for c in c_list:\n",
    "        #creating model for each c value\n",
    "        SVM1 = svm.SVC(C=c, kernel='linear')\n",
    "        #evaluating the model with each scorer and storing the results in a list for each scorer\n",
    "        globals()['svm_'+scorer].append(cross_validate(SVM1, age_train_X, age_y, scoring = scorer)['test_score'].mean())\n",
    "#averaging the score from each scorer for each c value and finding the best c\n",
    "average_svm_score = [(x + y + z)/3 for x, y, z in zip(svm_accuracy, svm_f1_weighted, svm_jaccard_weighted)]\n",
    "best_c = c_list[average_svm_score.index(max(average_svm_score))]\n",
    "for scorer in scoring:\n",
    "    #getting each score for the best c\n",
    "    globals()['best_'+scorer] = globals()['svm_'+scorer][c_list.index(best_c)]\n",
    "#printing the results\n",
    "age_SVM = svm.SVC(C=best_c, kernel='linear').fit(age_train_X, age_y)\n",
    "print('The best c was {}, with a f1_score of {}, a jaccard_score of {}, an accuracy score of {}, and an overall score of {}'.format(best_c, best_f1_weighted, best_jaccard_weighted, best_accuracy, mean([best_f1_weighted, best_jaccard_weighted, best_accuracy])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best c was 0.02, with a f1_score of 0.7573087613965847, a jaccard_score of 0.6137053207847842, an accuracy score of 0.7626984126984127, and an overall score of 0.7112374982932606\n"
     ]
    }
   ],
   "source": [
    "#making list of c values\n",
    "c_list = np.arange(.01, 0.1, 0.01).tolist()\n",
    "for scorer in scoring:\n",
    "    #making variable for each scorer\n",
    "    globals()['svm_'+scorer] = []\n",
    "    for c in c_list:\n",
    "        #creating model for each c value\n",
    "        SVM1 = svm.SVC(C=c, kernel='linear')\n",
    "        #evaluating the model with each scorer and storing the results in a list for each scorer\n",
    "        globals()['svm_'+scorer].append(cross_validate(SVM1, no_age_train_X, no_age_y, scoring = scorer)['test_score'].mean())\n",
    "#averaging the score from each scorer for each c value and finding the best c\n",
    "average_svm_score = [(x + y + z)/3 for x, y, z in zip(svm_accuracy, svm_f1_weighted, svm_jaccard_weighted)]\n",
    "best_c = c_list[average_svm_score.index(max(average_svm_score))]\n",
    "for scorer in scoring:\n",
    "    #getting each score for the best c\n",
    "    globals()['best_'+scorer] = globals()['svm_'+scorer][c_list.index(best_c)]\n",
    "#printing the results\n",
    "no_age_SVM = svm.SVC(C=best_c, kernel='linear').fit(no_age_train_X, no_age_y)\n",
    "print('The best c was {}, with a f1_score of {}, a jaccard_score of {}, an accuracy score of {}, and an overall score of {}'.format(best_c, best_f1_weighted, best_jaccard_weighted, best_accuracy, mean([best_f1_weighted, best_jaccard_weighted, best_accuracy])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best depth was 6, with a f1_score of 0.7916774968326908, a jaccard_score of 0.6582187399605273, an accuracy score of 0.7949867034374076, and an overall score of 0.7482943134102086\n"
     ]
    }
   ],
   "source": [
    "#making list of depths\n",
    "depths = np.arange(1, 10, 1)\n",
    "for scorer in scoring:\n",
    "    #making variable for each scorer\n",
    "    globals()['tree_'+scorer] = []\n",
    "    for depth in depths:\n",
    "        #creating model for each depth\n",
    "        tree = DecisionTreeClassifier(max_depth = depth, criterion='entropy')\n",
    "        #evaluating the model with each scorer and storing the results in a list for each scorer\n",
    "        globals()['tree_'+scorer].append(cross_validate(tree, age_train_X, age_y, scoring = scorer)['test_score'].mean())\n",
    "#averaging the score from each scorer for each depth and finding the best depth\n",
    "average_tree_score = [(x + y + z)/3 for x, y, z in zip(tree_accuracy, tree_f1_weighted, tree_jaccard_weighted)]\n",
    "best_depth = depths[average_tree_score.index(max(average_tree_score))]\n",
    "for scorer in scoring:\n",
    "    #getting each score for the best depth\n",
    "    globals()['best_'+scorer] = globals()['tree_'+scorer][best_depth]\n",
    "age_tree = DecisionTreeClassifier(max_depth = best_depth, criterion='entropy').fit(age_train_X, age_y)\n",
    "#printing the results\n",
    "print('The best depth was {}, with a f1_score of {}, a jaccard_score of {}, an accuracy score of {}, and an overall score of {}'.format(best_depth, best_f1_weighted, best_jaccard_weighted, best_accuracy, mean([best_f1_weighted, best_jaccard_weighted, best_accuracy])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best depth was 1, with a f1_score of 0.7013452253083722, a jaccard_score of 0.5526907946926922, an accuracy score of 0.7069841269841269, and an overall score of 0.6536733823283971\n"
     ]
    }
   ],
   "source": [
    "#making list of depths\n",
    "depths = np.arange(1, 10, 1)\n",
    "for scorer in scoring:\n",
    "    #making variable for each scorer\n",
    "    globals()['tree_'+scorer] = []\n",
    "    for depth in depths:\n",
    "        #creating model for each depth\n",
    "        tree = DecisionTreeClassifier(max_depth = depth, criterion='entropy')\n",
    "        #evaluating the model with each scorer and storing the results in a list for each scorer\n",
    "        globals()['tree_'+scorer].append(cross_validate(tree, no_age_train_X, no_age_y, scoring = scorer)['test_score'].mean())\n",
    "#averaging the score from each scorer for each depth and finding the best depth\n",
    "average_tree_score = [(x + y + z)/3 for x, y, z in zip(tree_accuracy, tree_f1_weighted, tree_jaccard_weighted)]\n",
    "best_depth = depths[average_tree_score.index(max(average_tree_score))]\n",
    "for scorer in scoring:\n",
    "    #getting each score for the best depth\n",
    "    globals()['best_'+scorer] = globals()['tree_'+scorer][best_depth]\n",
    "no_age_tree = DecisionTreeClassifier(max_depth = best_depth, criterion='entropy').fit(no_age_train_X, no_age_y)\n",
    "#printing the results\n",
    "print('The best depth was {}, with a f1_score of {}, a jaccard_score of {}, an accuracy score of {}, and an overall score of {}'.format(best_depth, best_f1_weighted, best_jaccard_weighted, best_accuracy, mean([best_f1_weighted, best_jaccard_weighted, best_accuracy])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best c was 0.01, with a f1_score of 0.7857771824748125, a jaccard_score of 0.6544378195927134, a logloss of -0.5054215541939621, an accuracy score of 0.7935881020388063, and an overall score of 0.7446010347021107\n"
     ]
    }
   ],
   "source": [
    "log_scoring = scoring = ['accuracy', 'f1_weighted', 'jaccard_weighted', 'neg_log_loss']\n",
    "#making list of c values\n",
    "log_c_list = np.arange(.01, 0.1, 0.01).tolist()\n",
    "for scorer in log_scoring:\n",
    "    #making variable for each scorer\n",
    "    globals()['lr_'+scorer] = []\n",
    "    for c in log_c_list:\n",
    "        #creating model for each c value\n",
    "        LR1 = LogisticRegression(C=c, solver='saga')\n",
    "        #evaluating the model with each scorer and storing the results in a list for each scorer\n",
    "        globals()['lr_'+scorer].append(cross_validate(LR1, age_train_X, age_y, scoring = scorer)['test_score'].mean())\n",
    "#averaging the score from each scorer for each c value and finding the best c\n",
    "average_lr_score = [(x + y + z)/3 for x, y, z in zip(lr_accuracy, lr_f1_weighted, lr_jaccard_weighted)]\n",
    "best_log_c = log_c_list[average_lr_score.index(max(average_lr_score))]\n",
    "for scorer in log_scoring:\n",
    "    #getting each score for the best c\n",
    "    globals()['best_'+scorer] = globals()['lr_'+scorer][log_c_list.index(best_log_c)]\n",
    "#printing the results\n",
    "age_LR = LogisticRegression(C=c, solver='saga').fit(age_train_X, age_y)\n",
    "print('The best c was {}, with a f1_score of {}, a jaccard_score of {}, a logloss of {}, an accuracy score of {}, and an overall score of {}'.format(best_log_c, best_f1_weighted, best_jaccard_weighted, best_neg_log_loss, best_accuracy, mean([best_f1_weighted, best_jaccard_weighted, best_accuracy])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best c was 0.06999999999999999, with a f1_score of 0.7167110457387195, a jaccard_score of 0.5701116158070618, a logloss of -0.5420149591881949, an accuracy score of 0.7238095238095239, and an overall score of 0.6702107284517684\n"
     ]
    }
   ],
   "source": [
    "log_scoring = scoring = ['accuracy', 'f1_weighted', 'jaccard_weighted', 'neg_log_loss']\n",
    "#making list of c values\n",
    "log_c_list = np.arange(.01, 0.1, 0.01).tolist()\n",
    "for scorer in log_scoring:\n",
    "    #making variable for each scorer\n",
    "    globals()['lr_'+scorer] = []\n",
    "    for c in log_c_list:\n",
    "        #creating model for each c value\n",
    "        LR1 = LogisticRegression(C=c, solver='saga')\n",
    "        #evaluating the model with each scorer and storing the results in a list for each scorer\n",
    "        globals()['lr_'+scorer].append(cross_validate(LR1, no_age_train_X, no_age_y, scoring = scorer)['test_score'].mean())\n",
    "#averaging the score from each scorer for each c value and finding the best c\n",
    "average_lr_score = [(x + y + z)/3 for x, y, z in zip(lr_accuracy, lr_f1_weighted, lr_jaccard_weighted)]\n",
    "best_log_c = log_c_list[average_lr_score.index(max(average_lr_score))]\n",
    "for scorer in log_scoring:\n",
    "    #getting each score for the best c\n",
    "    globals()['best_'+scorer] = globals()['lr_'+scorer][log_c_list.index(best_log_c)]\n",
    "#printing the results\n",
    "no_age_LR = LogisticRegression(C=c, solver='saga').fit(no_age_train_X, no_age_y)\n",
    "print('The best c was {}, with a f1_score of {}, a jaccard_score of {}, a logloss of {}, an accuracy score of {}, and an overall score of {}'.format(best_log_c, best_f1_weighted, best_jaccard_weighted, best_neg_log_loss, best_accuracy, mean([best_f1_weighted, best_jaccard_weighted, best_accuracy])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_neighHat = age_neigh.predict(age_test_X).tolist()\n",
    "age_LRHat = age_LR.predict(age_test_X).tolist()\n",
    "age_treeHat = age_tree.predict(age_test_X).tolist()\n",
    "age_SVMHat = age_SVM.predict(age_test_X).tolist()\n",
    "no_age_neighHat = no_age_neigh.predict(no_age_test_X).tolist()\n",
    "no_age_LRHat = no_age_LR.predict(no_age_test_X).tolist()\n",
    "no_age_treeHat = no_age_tree.predict(no_age_test_X).tolist()\n",
    "no_age_SVMHat = no_age_SVM.predict(no_age_test_X).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-88-acb1ca38e037>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_age_predicting['Survived']=globals()['no_age_{}Hat'.format(model)]\n"
     ]
    }
   ],
   "source": [
    "models = ['neigh', 'LR', 'tree', 'SVM']\n",
    "for model in models:\n",
    "    age_predicting['Survived']=globals()['age_{}Hat'.format(model)]\n",
    "    no_age_predicting['Survived']=globals()['no_age_{}Hat'.format(model)]\n",
    "    submission_df = age_predicting[['PassengerId', 'Survived']].append(no_age_predicting[['PassengerId', 'Survived']])\n",
    "    submission_df.sort_values('PassengerId', inplace = True)\n",
    "    submission_df.to_csv('titanic_{}_submission.csv'.format(model), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_submission_df=pd.read_csv('titanic_tree_submission.csv')\n",
    "test_submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
